# Network AI Service - ë°°í¬ ê°€ì´ë“œ

## ğŸš€ ë°°í¬ í™˜ê²½ ì¤€ë¹„

### ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

#### ìµœì†Œ ì‚¬ì–‘

- **CPU**: 2 ì½”ì–´ ì´ìƒ
- **ë©”ëª¨ë¦¬**: 4GB RAM ì´ìƒ
- **ì €ì¥ê³µê°„**: 10GB ì´ìƒ ì—¬ìœ  ê³µê°„
- **ë„¤íŠ¸ì›Œí¬**: ì¸í„°ë„· ì—°ê²° (íŒ¨í‚¤ì§€ ë‹¤ìš´ë¡œë“œìš©)

#### ê¶Œì¥ ì‚¬ì–‘

- **CPU**: 4 ì½”ì–´ ì´ìƒ (Intel i5/AMD Ryzen 5 ê¸‰ ì´ìƒ)
- **ë©”ëª¨ë¦¬**: 8GB RAM ì´ìƒ
- **ì €ì¥ê³µê°„**: SSD 20GB ì´ìƒ
- **ë„¤íŠ¸ì›Œí¬**: ê¸°ê°€ë¹„íŠ¸ ì´ë”ë„·

#### ìš´ì˜ì²´ì œ

- **Windows**: Windows 10/11 (64ë¹„íŠ¸)
- **Linux**: Ubuntu 20.04 LTS ì´ìƒ, CentOS 8 ì´ìƒ
- **Python**: 3.9 ì´ìƒ

## ğŸ³ Dockerë¥¼ ì´ìš©í•œ ë°°í¬

### 1. Docker ì„¤ì¹˜

```bash
# Windows (PowerShell ê´€ë¦¬ì ê¶Œí•œ)
winget install Docker.DockerDesktop

# Linux (Ubuntu)
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh
sudo usermod -aG docker $USER
```

### 2. í”„ë¡œì íŠ¸ í´ë¡  ë° ë¹Œë“œ

```bash
cd c:\My_Project\WS\network_ai_service

# Docker ì´ë¯¸ì§€ ë¹Œë“œ
docker build -t network-ai-service:latest .

# ë¹Œë“œ í™•ì¸
docker images | grep network-ai-service
```

### 3. Docker Composeë¡œ ì„œë¹„ìŠ¤ ì‹¤í–‰

```bash
# ì„œë¹„ìŠ¤ ì‹œì‘
docker-compose up -d

# ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
docker-compose ps

# ë¡œê·¸ í™•ì¸
docker-compose logs -f network-ai-service
```

### 4. ì„œë¹„ìŠ¤ ì ‘ì† í™•ì¸

```bash
# API í—¬ìŠ¤ ì²´í¬
curl http://localhost:8000/api/v1/health

# Swagger UI ì ‘ì†
# http://localhost:8000/docs
```

## ğŸ”§ ìˆ˜ë™ ë°°í¬ (Python ê°€ìƒí™˜ê²½)

### 1. í”„ë¡œì íŠ¸ ì¤€ë¹„

```bash
# í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ë¡œ ì´ë™
cd c:\My_Project\WS\network_ai_service

# ê°€ìƒí™˜ê²½ ìƒì„±
python -m venv venv

# ê°€ìƒí™˜ê²½ í™œì„±í™” (Windows)
venv\Scripts\activate

# ê°€ìƒí™˜ê²½ í™œì„±í™” (Linux)
source venv/bin/activate

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt
```

### 2. í™˜ê²½ ì„¤ì •

```bash
# í™˜ê²½ ë³€ìˆ˜ íŒŒì¼ ìƒì„±
copy config\production.yaml.example config\production.yaml

# ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
python scripts\init_database.py --env production

# ëª¨ë¸ ë””ë ‰í† ë¦¬ ìƒì„±
mkdir models data logs
```

### 3. ì„œë¹„ìŠ¤ ì‹œì‘

```bash
# ê°œë°œ ì„œë²„ (í…ŒìŠ¤íŠ¸ìš©)
python -m uvicorn src.api.main:app --host 0.0.0.0 --port 8000

# í”„ë¡œë•ì…˜ ì„œë²„ (Gunicorn ì‚¬ìš©)
gunicorn src.api.main:app -w 4 -k uvicorn.workers.UvicornWorker --bind 0.0.0.0:8000
```

## âš™ï¸ í™˜ê²½ë³„ ì„¤ì •

### ê°œë°œ í™˜ê²½ (config/development.yaml)

```yaml
environment: development
debug: true
log_level: DEBUG

api:
  host: "0.0.0.0"
  port: 8000
  reload: true
  workers: 1

database:
  url: "sqlite:///./data/network_ai_dev.db"
  echo: true

ml_models:
  auto_retrain: false
  retrain_interval_hours: 24
  model_store_path: "./models"

data_collection:
  interval_seconds: 5.0
  buffer_size: 100
  enable_packet_capture: false

monitoring:
  enable_prometheus: true
  prometheus_port: 9090
  log_file: "./logs/network_ai_dev.log"
```

### í”„ë¡œë•ì…˜ í™˜ê²½ (config/production.yaml)

```yaml
environment: production
debug: false
log_level: INFO

api:
  host: "0.0.0.0"
  port: 8000
  reload: false
  workers: 4

database:
  url: "sqlite:///./data/network_ai.db"
  echo: false
  pool_size: 10
  max_overflow: 20

ml_models:
  auto_retrain: true
  retrain_interval_hours: 168 # 7 days
  model_store_path: "./models"
  backup_old_models: true

data_collection:
  interval_seconds: 1.0
  buffer_size: 1000
  enable_packet_capture: true
  max_connections_per_scan: 10000

security:
  api_key_required: true
  jwt_secret_key: "your-secret-key-here"
  jwt_expire_hours: 24
  cors_origins: ["http://localhost:3000"]

monitoring:
  enable_prometheus: true
  prometheus_port: 9090
  log_file: "./logs/network_ai.log"
  log_rotation: true
  max_log_size_mb: 100
  backup_count: 5

performance:
  max_concurrent_requests: 100
  request_timeout_seconds: 30
  cache_ttl_seconds: 300
```

## ğŸ” ë³´ì•ˆ ì„¤ì •

### 1. API í‚¤ ìƒì„±

```bash
# API í‚¤ ìƒì„± ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
python scripts/generate_api_key.py

# ì¶œë ¥ ì˜ˆì‹œ
# API Key: ai_service_key_abc123def456
# JWT Secret: jwt_secret_xyz789uvw
```

### 2. SSL/TLS ì„¤ì • (í”„ë¡œë•ì…˜)

```bash
# Let's Encrypt ì¸ì¦ì„œ ìƒì„± (Linux)
sudo apt install certbot
sudo certbot certonly --standalone -d your-domain.com

# Windowsì—ì„œëŠ” IIS ë˜ëŠ” nginx í”„ë¡ì‹œ ì‚¬ìš© ê¶Œì¥
```

### 3. ë°©í™”ë²½ ì„¤ì •

```bash
# Windows ë°©í™”ë²½ (PowerShell ê´€ë¦¬ì ê¶Œí•œ)
New-NetFirewallRule -DisplayName "Network AI Service" -Direction Inbound -Port 8000 -Protocol TCP -Action Allow

# Linux iptables
sudo iptables -A INPUT -p tcp --dport 8000 -j ACCEPT
sudo iptables-save
```

## ğŸ“Š ëª¨ë‹ˆí„°ë§ ì„¤ì •

### 1. Prometheus ì„¤ì •

```yaml
# config/prometheus.yml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: "network-ai-service"
    static_configs:
      - targets: ["localhost:8000"]
    metrics_path: "/metrics"
    scrape_interval: 5s
```

### 2. Grafana ëŒ€ì‹œë³´ë“œ

```bash
# Grafana ì»¨í…Œì´ë„ˆ ì‹œì‘
docker run -d -p 3000:3000 --name grafana grafana/grafana

# ê¸°ë³¸ ë¡œê·¸ì¸: admin/admin
# URL: http://localhost:3000

# ë°ì´í„° ì†ŒìŠ¤ ì¶”ê°€: Prometheus (http://localhost:9090)
```

### 3. ì•Œë¦¼ ì„¤ì •

```python
# scripts/setup_alerts.py
import requests

SLACK_WEBHOOK_URL = "https://hooks.slack.com/services/YOUR/WEBHOOK/URL"

def send_alert(message: str, severity: str = "warning"):
    payload = {
        "text": f"ğŸš¨ Network AI Service Alert [{severity.upper()}]",
        "attachments": [
            {
                "color": "danger" if severity == "critical" else "warning",
                "text": message,
                "ts": int(time.time())
            }
        ]
    }
    requests.post(SLACK_WEBHOOK_URL, json=payload)
```

## ğŸ”„ ìë™ ë°°í¬ ì„¤ì •

### 1. GitHub Actions ì›Œí¬í”Œë¡œìš°

```yaml
# .github/workflows/deploy.yml
name: Deploy to Production

on:
  push:
    branches: [main]
    tags: ["v*"]

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: 3.9

      - name: Run tests
        run: |
          pip install -r requirements.txt
          pip install -r requirements-dev.txt
          pytest

      - name: Build Docker image
        run: |
          docker build -t network-ai-service:${{ github.sha }} .
          docker tag network-ai-service:${{ github.sha }} network-ai-service:latest

      - name: Deploy to server
        run: |
          # SSHë¥¼ í†µí•œ ì›ê²© ë°°í¬
          echo "${{ secrets.DEPLOY_KEY }}" | tr -d '\r' > deploy_key
          chmod 600 deploy_key
          ssh -i deploy_key -o StrictHostKeyChecking=no ${{ secrets.DEPLOY_USER }}@${{ secrets.DEPLOY_HOST }} << 'EOF'
            cd /opt/network-ai-service
            docker-compose pull
            docker-compose up -d
            docker system prune -f
          EOF
```

### 2. ë¬´ì¤‘ë‹¨ ë°°í¬ ìŠ¤í¬ë¦½íŠ¸

```bash
#!/bin/bash
# scripts/deploy.sh

set -e

SERVICE_NAME="network-ai-service"
BACKUP_NAME="${SERVICE_NAME}-backup"

echo "ğŸš€ Starting deployment..."

# í˜„ì¬ ì„œë¹„ìŠ¤ ë°±ì—…
echo "ğŸ“¦ Creating backup..."
docker tag $SERVICE_NAME:latest $BACKUP_NAME:latest || echo "No existing image to backup"

# ìƒˆ ì´ë¯¸ì§€ ë¹Œë“œ
echo "ğŸ”¨ Building new image..."
docker build -t $SERVICE_NAME:latest .

# í—¬ìŠ¤ì²´í¬ í•¨ìˆ˜
health_check() {
    local max_attempts=30
    local attempt=0

    while [ $attempt -lt $max_attempts ]; do
        if curl -s http://localhost:8000/api/v1/health | grep -q "healthy"; then
            echo "âœ… Health check passed"
            return 0
        fi

        echo "â³ Waiting for service to be ready... ($((attempt + 1))/$max_attempts)"
        sleep 2
        ((attempt++))
    done

    echo "âŒ Health check failed"
    return 1
}

# ì„œë¹„ìŠ¤ ì¬ì‹œì‘
echo "ğŸ”„ Restarting service..."
docker-compose up -d $SERVICE_NAME

# í—¬ìŠ¤ì²´í¬
if health_check; then
    echo "âœ… Deployment successful!"
    # ë°±ì—… ì´ë¯¸ì§€ ì •ë¦¬
    docker rmi $BACKUP_NAME:latest 2>/dev/null || echo "No backup to clean"
else
    echo "âŒ Deployment failed, rolling back..."
    # ë¡¤ë°±
    docker tag $BACKUP_NAME:latest $SERVICE_NAME:latest
    docker-compose up -d $SERVICE_NAME

    if health_check; then
        echo "âœ… Rollback successful"
    else
        echo "ğŸ’¥ Rollback failed - manual intervention required!"
        exit 1
    fi
fi

echo "ğŸ“Š Current service status:"
docker-compose ps $SERVICE_NAME
```

## ğŸ”§ ìš´ì˜ ê´€ë¦¬

### 1. ë¡œê·¸ ê´€ë¦¬

```bash
# ë¡œê·¸ í™•ì¸
docker-compose logs -f network-ai-service

# ë¡œê·¸ ë¡œí…Œì´ì…˜ ì„¤ì • (Linux)
sudo tee /etc/logrotate.d/network-ai-service << EOF
/opt/network-ai-service/logs/*.log {
    daily
    missingok
    rotate 7
    compress
    delaycompress
    notifempty
    copytruncate
}
EOF
```

### 2. ë°±ì—… ì„¤ì •

```bash
#!/bin/bash
# scripts/backup.sh

BACKUP_DIR="/opt/backups/network-ai-service"
DATE=$(date +%Y%m%d_%H%M%S)

# ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—…
echo "ğŸ—„ï¸ Backing up database..."
mkdir -p $BACKUP_DIR
cp data/network_ai.db $BACKUP_DIR/network_ai_$DATE.db

# ëª¨ë¸ ë°±ì—…
echo "ğŸ§  Backing up models..."
tar -czf $BACKUP_DIR/models_$DATE.tar.gz models/

# ì„¤ì • ë°±ì—…
echo "âš™ï¸ Backing up configurations..."
tar -czf $BACKUP_DIR/config_$DATE.tar.gz config/

# ì˜¤ë˜ëœ ë°±ì—… ì •ë¦¬ (30ì¼ ì´ìƒ)
echo "ğŸ§¹ Cleaning old backups..."
find $BACKUP_DIR -type f -mtime +30 -delete

echo "âœ… Backup completed: $DATE"
```

### 3. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

```bash
# ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§
docker stats network-ai-service

# API ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
ab -n 1000 -c 10 http://localhost:8000/api/v1/health

# ë°ì´í„°ë² ì´ìŠ¤ í¬ê¸° í™•ì¸
du -sh data/network_ai.db
```

## ğŸš¨ ì¥ì•  ëŒ€ì‘

### ì¼ë°˜ì ì¸ ë¬¸ì œ í•´ê²°

#### 1. ì„œë¹„ìŠ¤ê°€ ì‹œì‘ë˜ì§€ ì•ŠëŠ” ê²½ìš°

```bash
# ë¡œê·¸ í™•ì¸
docker-compose logs network-ai-service

# í¬íŠ¸ ì¶©ëŒ í™•ì¸
netstat -ano | findstr :8000

# ê¶Œí•œ ë¬¸ì œ í™•ì¸ (Linux)
ls -la data/ models/ logs/
```

#### 2. ë©”ëª¨ë¦¬ ë¶€ì¡±

```bash
# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
docker stats

# ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ê°•ì œ ì‹¤í–‰
curl -X POST http://localhost:8000/api/v1/admin/gc

# ì»¨í…Œì´ë„ˆ ì¬ì‹œì‘
docker-compose restart network-ai-service
```

#### 3. ë°ì´í„°ë² ì´ìŠ¤ ë¬¸ì œ

```bash
# ë°ì´í„°ë² ì´ìŠ¤ ë¬´ê²°ì„± ê²€ì‚¬
python scripts/check_database.py

# ë°ì´í„°ë² ì´ìŠ¤ ë³µêµ¬
python scripts/repair_database.py

# ë°±ì—…ì—ì„œ ë³µì›
cp /opt/backups/network-ai-service/network_ai_20250918_140000.db data/network_ai.db
```

### ë¹„ìƒ ì—°ë½ì²˜ ë° ì ˆì°¨

1. **ì‹œìŠ¤í…œ ê´€ë¦¬ì**: admin@yourcompany.com
2. **ê°œë°œíŒ€ ë¦¬ë”**: dev-lead@yourcompany.com
3. **24ì‹œê°„ ëª¨ë‹ˆí„°ë§**: monitoring@yourcompany.com

### ë³µêµ¬ ì ˆì°¨

1. ì¦‰ì‹œ ë°±ì—…ì—ì„œ ë³µêµ¬
2. ë¬¸ì œ ì›ì¸ ë¶„ì„
3. ì„ì‹œ í•´ê²°ì±… ì ìš©
4. ê·¼ë³¸ ì›ì¸ í•´ê²°
5. ì¬ë°œ ë°©ì§€ ì¡°ì¹˜

ì´ ë°°í¬ ê°€ì´ë“œë¥¼ í†µí•´ ì•ˆì •ì ì´ê³  í™•ì¥ ê°€ëŠ¥í•œ Network AI Serviceë¥¼ ìš´ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
