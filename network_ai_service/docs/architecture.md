# Network AI Service - ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ì„¤ê³„

## ğŸ—ï¸ ì „ì²´ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### ì‹œìŠ¤í…œ ê°œìš”

WindowsSentinel Network AI ServiceëŠ” ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„¤ê³„ëœ ì‹¤ì‹œê°„ ë„¤íŠ¸ì›Œí¬ ì´ìƒ íƒì§€ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

```mermaid
graph TB
    subgraph "Windows System"
        A[Network Interfaces]
        B[Running Processes]
        C[System Resources]
    end

    subgraph "Python AI Service"
        D[Data Collector]
        E[Feature Engineer]
        F[ML Pipeline]
        G[Prediction Engine]
        H[API Gateway]
    end

    subgraph "Storage Layer"
        I[SQLite DB]
        J[Model Store]
        K[Cache Layer]
    end

    subgraph "C# Application"
        L[WPF UI]
        M[Business Logic]
        N[Integration Layer]
    end

    A --> D
    B --> D
    C --> D
    D --> E
    E --> F
    F --> G
    G --> H
    H --> N
    N --> M
    M --> L

    D --> I
    F --> J
    G --> K
```

## ğŸ”§ ì»´í¬ë„ŒíŠ¸ ì„¤ê³„

### 1. Data Collection Layer

#### NetworkCollector

```python
class NetworkCollector:
    """ì‹¤ì‹œê°„ ë„¤íŠ¸ì›Œí¬ ì—°ê²° ë°ì´í„° ìˆ˜ì§‘"""

    def __init__(self):
        self.collection_interval = 1.0  # 1ì´ˆë§ˆë‹¤ ìˆ˜ì§‘
        self.buffer_size = 1000

    async def collect_connections(self) -> List[ConnectionData]:
        """í™œì„± ë„¤íŠ¸ì›Œí¬ ì—°ê²° ìˆ˜ì§‘"""

    async def collect_traffic_stats(self) -> List[TrafficData]:
        """ë„¤íŠ¸ì›Œí¬ ì¸í„°í˜ì´ìŠ¤ í†µê³„ ìˆ˜ì§‘"""

    async def collect_process_network_info(self) -> List[ProcessNetworkData]:
        """í”„ë¡œì„¸ìŠ¤ë³„ ë„¤íŠ¸ì›Œí¬ ì‚¬ìš©ëŸ‰ ìˆ˜ì§‘"""
```

#### ProcessCollector

```python
class ProcessCollector:
    """í”„ë¡œì„¸ìŠ¤ ì •ë³´ ìˆ˜ì§‘"""

    async def collect_process_info(self) -> List[ProcessInfo]:
        """ì‹¤í–‰ ì¤‘ì¸ í”„ë¡œì„¸ìŠ¤ ì •ë³´ ìˆ˜ì§‘"""

    async def collect_process_network_usage(self) -> Dict[int, NetworkUsage]:
        """í”„ë¡œì„¸ìŠ¤ë³„ ë„¤íŠ¸ì›Œí¬ ì‚¬ìš©ëŸ‰ ìˆ˜ì§‘"""
```

### 2. Data Processing Layer

#### FeatureEngineer

```python
class FeatureEngineer:
    """íŠ¹ì§• ì¶”ì¶œ ë° ì „ì²˜ë¦¬"""

    def extract_connection_features(self, conn_data: ConnectionData) -> ConnectionFeatures:
        """ì—°ê²° ê¸°ë°˜ íŠ¹ì§• ì¶”ì¶œ"""

    def extract_temporal_features(self, time_series: List[ConnectionData]) -> TemporalFeatures:
        """ì‹œê³„ì—´ íŠ¹ì§• ì¶”ì¶œ"""

    def extract_statistical_features(self, data_window: List[ConnectionData]) -> StatisticalFeatures:
        """í†µê³„ì  íŠ¹ì§• ì¶”ì¶œ"""
```

#### DataProcessor

```python
class DataProcessor:
    """ë°ì´í„° ì „ì²˜ë¦¬ ë° ì •ê·œí™”"""

    def normalize_features(self, features: RawFeatures) -> NormalizedFeatures:
        """íŠ¹ì§• ì •ê·œí™”"""

    def handle_missing_values(self, data: DataFrame) -> DataFrame:
        """ê²°ì¸¡ê°’ ì²˜ë¦¬"""

    def create_sliding_windows(self, data: List, window_size: int) -> List[List]:
        """ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ìƒì„±"""
```

### 3. Machine Learning Layer

#### BaselineLearner

```python
class BaselineLearner:
    """ì •ìƒ ë„¤íŠ¸ì›Œí¬ íŒ¨í„´ í•™ìŠµ"""

    def __init__(self):
        self.models = {
            'isolation_forest': IsolationForest(),
            'one_class_svm': OneClassSVM(),
            'local_outlier_factor': LocalOutlierFactor()
        }

    async def train_baseline_models(self, normal_data: DataFrame) -> Dict[str, Model]:
        """ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ í•™ìŠµ"""

    async def evaluate_models(self, test_data: DataFrame) -> Dict[str, Metrics]:
        """ëª¨ë¸ í‰ê°€"""
```

#### AnomalyDetector

```python
class AnomalyDetector:
    """ì‹¤ì‹œê°„ ì´ìƒ íƒì§€"""

    def __init__(self):
        self.ensemble_models = []
        self.threshold_manager = ThresholdManager()

    async def predict_anomaly(self, features: Features) -> AnomalyResult:
        """ì´ìƒ íƒì§€ ì˜ˆì¸¡"""

    async def predict_batch(self, feature_batch: List[Features]) -> List[AnomalyResult]:
        """ë°°ì¹˜ ì˜ˆì¸¡"""
```

#### ModelEnsemble

```python
class ModelEnsemble:
    """ì•™ìƒë¸” ëª¨ë¸ ê´€ë¦¬"""

    def __init__(self):
        self.voting_classifier = VotingClassifier()
        self.stacking_classifier = StackingClassifier()
        self.dynamic_weights = DynamicWeights()

    def combine_predictions(self, predictions: List[Prediction]) -> FinalPrediction:
        """ì˜ˆì¸¡ ê²°ê³¼ ê²°í•©"""

    def update_model_weights(self, performance_metrics: Dict[str, float]):
        """ëª¨ë¸ ê°€ì¤‘ì¹˜ ë™ì  ì¡°ì •"""
```

### 4. API Layer

#### FastAPI ì„œë²„ êµ¬ì¡°

```python
from fastapi import FastAPI, WebSocket
from fastapi.middleware.cors import CORSMiddleware

app = FastAPI(
    title="Network AI Service API",
    version="1.0.0",
    description="Real-time network anomaly detection service"
)

# ë¯¸ë“¤ì›¨ì–´ ì„¤ì •
app.add_middleware(CORSMiddleware, allow_origins=["*"])

# REST ì—”ë“œí¬ì¸íŠ¸
@app.post("/api/v1/analyze")
async def analyze_network_data(data: NetworkAnalysisRequest) -> NetworkAnalysisResponse:
    """ë„¤íŠ¸ì›Œí¬ ë°ì´í„° ë¶„ì„"""

@app.post("/api/v1/train")
async def train_models(config: TrainingConfig) -> TrainingResponse:
    """ëª¨ë¸ í•™ìŠµ ì‹œì‘"""

@app.get("/api/v1/models/status")
async def get_model_status() -> ModelStatusResponse:
    """ëª¨ë¸ ìƒíƒœ ì¡°íšŒ"""

# WebSocket ì—”ë“œí¬ì¸íŠ¸
@app.websocket("/ws/realtime")
async def websocket_endpoint(websocket: WebSocket):
    """ì‹¤ì‹œê°„ ë¶„ì„ ê²°ê³¼ ìŠ¤íŠ¸ë¦¬ë°"""
```

### 5. Storage Layer

#### Database Schema

```sql
-- ë„¤íŠ¸ì›Œí¬ ì—°ê²° ë°ì´í„°
CREATE TABLE network_connections (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    timestamp DATETIME NOT NULL,
    process_id INTEGER,
    process_name TEXT,
    local_ip TEXT,
    local_port INTEGER,
    remote_ip TEXT,
    remote_port INTEGER,
    protocol TEXT,
    state TEXT,
    bytes_sent INTEGER,
    bytes_received INTEGER
);

-- íŠ¹ì§• ë°ì´í„°
CREATE TABLE network_features (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    timestamp DATETIME NOT NULL,
    connection_id INTEGER,
    feature_vector TEXT,  -- JSON í˜•íƒœ
    label INTEGER DEFAULT 0,  -- 0: normal, 1: anomaly
    session_id TEXT,
    FOREIGN KEY (connection_id) REFERENCES network_connections(id)
);

-- ëª¨ë¸ ì„±ëŠ¥ ë©”íŠ¸ë¦­
CREATE TABLE model_metrics (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    model_name TEXT NOT NULL,
    timestamp DATETIME NOT NULL,
    accuracy REAL,
    precision_score REAL,
    recall REAL,
    f1_score REAL,
    auc_roc REAL,
    false_positive_rate REAL
);

-- ì˜ˆì¸¡ ê²°ê³¼
CREATE TABLE predictions (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    timestamp DATETIME NOT NULL,
    feature_id INTEGER,
    model_name TEXT,
    anomaly_score REAL,
    is_anomaly BOOLEAN,
    confidence REAL,
    explanation TEXT,
    FOREIGN KEY (feature_id) REFERENCES network_features(id)
);
```

## ğŸ“Š ë°ì´í„° í”Œë¡œìš°

### ì‹¤ì‹œê°„ ë°ì´í„° íŒŒì´í”„ë¼ì¸

```mermaid
sequenceDiagram
    participant NC as NetworkCollector
    participant FE as FeatureEngineer
    participant AD as AnomalyDetector
    participant API as API Gateway
    participant CS as C# Service

    NC->>FE: Raw Network Data
    FE->>FE: Feature Extraction
    FE->>AD: Processed Features
    AD->>AD: Anomaly Detection
    AD->>API: Prediction Result
    API->>CS: HTTP/WebSocket Response

    Note over NC,CS: ~10ms end-to-end latency
```

### ë°°ì¹˜ í•™ìŠµ íŒŒì´í”„ë¼ì¸

```mermaid
sequenceDiagram
    participant DB as Database
    participant DP as DataProcessor
    participant BL as BaselineLearner
    participant MS as ModelStore

    DB->>DP: Historical Data
    DP->>DP: Data Preprocessing
    DP->>BL: Clean Training Data
    BL->>BL: Model Training
    BL->>MS: Trained Models

    Note over DB,MS: Daily batch training
```

## ğŸ”„ í™•ì¥ì„± ì„¤ê³„

### ìˆ˜í‰ í™•ì¥ ê³ ë ¤ì‚¬í•­

#### 1. ë°ì´í„° ìˆ˜ì§‘ ìŠ¤ì¼€ì¼ë§

```python
class DistributedCollector:
    """ë¶„ì‚° ë°ì´í„° ìˆ˜ì§‘"""

    def __init__(self, node_id: str, coordinator_url: str):
        self.node_id = node_id
        self.coordinator = CoordinatorClient(coordinator_url)

    async def register_node(self):
        """ë…¸ë“œ ë“±ë¡"""

    async def collect_assigned_targets(self):
        """í• ë‹¹ëœ ëŒ€ìƒë§Œ ìˆ˜ì§‘"""
```

#### 2. ëª¨ë¸ ì„œë¹™ ë¶„ì‚°í™”

```python
class ModelServing:
    """ë¶„ì‚° ëª¨ë¸ ì„œë¹™"""

    def __init__(self, model_registry: ModelRegistry):
        self.registry = model_registry
        self.load_balancer = LoadBalancer()

    async def serve_prediction(self, request: PredictionRequest) -> PredictionResponse:
        """ìµœì  ëª¨ë¸ ì„œë²„ë¡œ ë¼ìš°íŒ…"""
```

### ì„±ëŠ¥ ìµœì í™”

#### 1. ë©”ëª¨ë¦¬ ìµœì í™”

- **íŠ¹ì§• ë²¡í„° ì••ì¶•**: í¬ì†Œ í–‰ë ¬ ì‚¬ìš©
- **ë°°ì¹˜ ì²˜ë¦¬**: ì—¬ëŸ¬ ìš”ì²­ ë™ì‹œ ì²˜ë¦¬
- **ë©”ëª¨ë¦¬ í’€ë§**: ê°ì²´ ì¬ì‚¬ìš©

#### 2. ì—°ì‚° ìµœì í™”

- **ëª¨ë¸ ì–‘ìí™”**: 16bit/8bit ì •ë°€ë„ ì‚¬ìš©
- **ë³‘ë ¬ ì²˜ë¦¬**: AsyncIO í™œìš©
- **ìºì‹±**: ìì£¼ ì‚¬ìš©ë˜ëŠ” ì˜ˆì¸¡ ê²°ê³¼ ìºì‹œ

## ğŸ›¡ï¸ ë³´ì•ˆ ì•„í‚¤í…ì²˜

### API ë³´ì•ˆ

```python
from fastapi_security import HTTPBearer, HTTPAuthorizationCredentials

security = HTTPBearer()

@app.post("/api/v1/analyze")
async def analyze_data(
    data: NetworkAnalysisRequest,
    credentials: HTTPAuthorizationCredentials = Depends(security)
):
    # JWT í† í° ê²€ì¦
    user = await verify_token(credentials.credentials)
    # ê¶Œí•œ í™•ì¸
    if not user.has_permission("analyze"):
        raise HTTPException(401, "Insufficient permissions")
```

### ë°ì´í„° ë³´ì•ˆ

- **ë°ì´í„° ìµëª…í™”**: IP ì£¼ì†Œ í•´ì‹±
- **ì „ì†¡ ì•”í˜¸í™”**: TLS 1.3 ì ìš©
- **ì €ì¥ ì•”í˜¸í™”**: SQLite ë°ì´í„°ë² ì´ìŠ¤ ì•”í˜¸í™”
- **ì ‘ê·¼ ë¡œê¹…**: ëª¨ë“  API í˜¸ì¶œ ê¸°ë¡

## ğŸ“ˆ ëª¨ë‹ˆí„°ë§ ì•„í‚¤í…ì²˜

### ë©”íŠ¸ë¦­ ìˆ˜ì§‘

```python
from prometheus_client import Counter, Histogram, Gauge

# ë¹„ì¦ˆë‹ˆìŠ¤ ë©”íŠ¸ë¦­
predictions_total = Counter('predictions_total', 'Total predictions made')
anomalies_detected = Counter('anomalies_detected', 'Anomalies detected')
model_accuracy = Gauge('model_accuracy', 'Current model accuracy')

# ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­
request_duration = Histogram('request_duration_seconds', 'Request duration')
memory_usage = Gauge('memory_usage_bytes', 'Memory usage')
```

### ì•Œë¦¼ ì‹œìŠ¤í…œ

```python
class AlertManager:
    """ì•Œë¦¼ ê´€ë¦¬"""

    def __init__(self):
        self.thresholds = {
            'accuracy_drop': 0.05,
            'high_anomaly_rate': 0.1,
            'system_overload': 0.8
        }

    async def check_alerts(self, metrics: Dict[str, float]):
        """ì„ê³„ê°’ ê¸°ë°˜ ì•Œë¦¼ í™•ì¸"""

    async def send_alert(self, alert: Alert):
        """ì•Œë¦¼ ë°œì†¡ (ì´ë©”ì¼, Slack, ì›¹í›…)"""
```

ì´ ì•„í‚¤í…ì²˜ëŠ” í™•ì¥ ê°€ëŠ¥í•˜ê³  ìœ ì§€ë³´ìˆ˜ê°€ ìš©ì´í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìœ¼ë©°, WindowsSentinel í”„ë¡œì íŠ¸ì™€ì˜ ì›í™œí•œ í†µí•©ì„ ë³´ì¥í•©ë‹ˆë‹¤.
