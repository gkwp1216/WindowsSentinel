# Network AI Service - ê°œë°œ ê°€ì´ë“œ

## ğŸš€ ê°œë°œ í™˜ê²½ ì„¤ì •

### ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

- **Python**: 3.9 ì´ìƒ
- **ìš´ì˜ì²´ì œ**: Windows 10/11 (ë¦¬ëˆ…ìŠ¤ ì§€ì› ì˜ˆì •)
- **ë©”ëª¨ë¦¬**: ìµœì†Œ 4GB, ê¶Œì¥ 8GB
- **ë””ìŠ¤í¬**: ìµœì†Œ 2GB ì—¬ìœ  ê³µê°„

### ê°œë°œ í™˜ê²½ êµ¬ì¶•

#### 1. í”„ë¡œì íŠ¸ í´ë¡  ë° ê°€ìƒí™˜ê²½ ì„¤ì •

```bash
cd c:\My_Project\WS\network_ai_service

# ê°€ìƒí™˜ê²½ ìƒì„±
python -m venv venv

# ê°€ìƒí™˜ê²½ í™œì„±í™” (Windows)
venv\Scripts\activate

# ê°€ìƒí™˜ê²½ í™œì„±í™” (Linux/Mac)
source venv/bin/activate

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt
```

#### 2. ê°œë°œìš© íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
pip install -r requirements-dev.txt
```

### í”„ë¡œì íŠ¸ êµ¬ì¡°

```
network_ai_service/
â”œâ”€â”€ src/                          # ì†ŒìŠ¤ ì½”ë“œ
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                   # ì• í”Œë¦¬ì¼€ì´ì…˜ ì§„ì…ì 
â”‚   â”‚
â”‚   â”œâ”€â”€ api/                      # FastAPI ê´€ë ¨
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py              # FastAPI ì•± ìƒì„±
â”‚   â”‚   â”œâ”€â”€ endpoints/           # API ì—”ë“œí¬ì¸íŠ¸
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ analysis.py      # ë¶„ì„ ê´€ë ¨ API
â”‚   â”‚   â”‚   â”œâ”€â”€ models.py        # ëª¨ë¸ ê´€ë ¨ API
â”‚   â”‚   â”‚   â””â”€â”€ system.py        # ì‹œìŠ¤í…œ ê´€ë ¨ API
â”‚   â”‚   â””â”€â”€ middleware/          # ë¯¸ë“¤ì›¨ì–´
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ auth.py          # ì¸ì¦ ë¯¸ë“¤ì›¨ì–´
â”‚   â”‚       â””â”€â”€ logging.py       # ë¡œê¹… ë¯¸ë“¤ì›¨ì–´
â”‚   â”‚
â”‚   â”œâ”€â”€ collectors/              # ë°ì´í„° ìˆ˜ì§‘
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py             # ê¸°ë³¸ ìˆ˜ì§‘ê¸° í´ë˜ìŠ¤
â”‚   â”‚   â”œâ”€â”€ network_collector.py # ë„¤íŠ¸ì›Œí¬ ë°ì´í„° ìˆ˜ì§‘
â”‚   â”‚   â”œâ”€â”€ process_collector.py # í”„ë¡œì„¸ìŠ¤ ë°ì´í„° ìˆ˜ì§‘
â”‚   â”‚   â””â”€â”€ traffic_analyzer.py  # íŠ¸ë˜í”½ ë¶„ì„
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                  # ML ëª¨ë¸
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base_model.py       # ê¸°ë³¸ ëª¨ë¸ í´ë˜ìŠ¤
â”‚   â”‚   â”œâ”€â”€ baseline_learner.py # ë² ì´ìŠ¤ë¼ì¸ í•™ìŠµ
â”‚   â”‚   â”œâ”€â”€ anomaly_detector.py # ì´ìƒ íƒì§€ ëª¨ë¸
â”‚   â”‚   â””â”€â”€ ensemble.py         # ì•™ìƒë¸” ëª¨ë¸
â”‚   â”‚
â”‚   â”œâ”€â”€ pipeline/               # ë°ì´í„° íŒŒì´í”„ë¼ì¸
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ data_processor.py   # ë°ì´í„° ì „ì²˜ë¦¬
â”‚   â”‚   â”œâ”€â”€ feature_engineer.py # íŠ¹ì§• ì—”ì§€ë‹ˆì–´ë§
â”‚   â”‚   â””â”€â”€ model_trainer.py    # ëª¨ë¸ í•™ìŠµ
â”‚   â”‚
â”‚   â”œâ”€â”€ storage/                # ë°ì´í„° ì €ì¥
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ database.py         # ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬
â”‚   â”‚   â”œâ”€â”€ model_store.py      # ëª¨ë¸ ì €ì¥ì†Œ
â”‚   â”‚   â””â”€â”€ cache.py            # ìºì‹œ ê´€ë¦¬
â”‚   â”‚
â”‚   â””â”€â”€ utils/                  # ìœ í‹¸ë¦¬í‹°
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ config.py           # ì„¤ì • ê´€ë¦¬
â”‚       â”œâ”€â”€ logger.py           # ë¡œê¹… ì„¤ì •
â”‚       â”œâ”€â”€ metrics.py          # ë©”íŠ¸ë¦­ ìˆ˜ì§‘
â”‚       â””â”€â”€ exceptions.py       # ì‚¬ìš©ì ì •ì˜ ì˜ˆì™¸
â”‚
â”œâ”€â”€ tests/                      # í…ŒìŠ¤íŠ¸ ì½”ë“œ
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py            # pytest ì„¤ì •
â”‚   â”œâ”€â”€ unit/                  # ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
â”‚   â”œâ”€â”€ integration/           # í†µí•© í…ŒìŠ¤íŠ¸
â”‚   â””â”€â”€ fixtures/              # í…ŒìŠ¤íŠ¸ ë°ì´í„°
â”‚
â”œâ”€â”€ scripts/                    # ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ init_database.py       # DB ì´ˆê¸°í™”
â”‚   â”œâ”€â”€ train_models.py        # ëª¨ë¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
â”‚   â””â”€â”€ generate_test_data.py  # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
â”‚
â”œâ”€â”€ config/                     # ì„¤ì • íŒŒì¼
â”‚   â”œâ”€â”€ development.yaml
â”‚   â”œâ”€â”€ production.yaml
â”‚   â””â”€â”€ test.yaml
â”‚
â”œâ”€â”€ models/                     # ì €ì¥ëœ ëª¨ë¸ íŒŒì¼
â”œâ”€â”€ data/                       # ë°ì´í„° íŒŒì¼
â”œâ”€â”€ logs/                       # ë¡œê·¸ íŒŒì¼
â”œâ”€â”€ docs/                       # ë¬¸ì„œ
â”œâ”€â”€ requirements.txt            # ìš´ì˜ ì˜ì¡´ì„±
â”œâ”€â”€ requirements-dev.txt        # ê°œë°œ ì˜ì¡´ì„±
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

## ğŸ› ï¸ ê°œë°œ ë„êµ¬ ë° ì»¨ë²¤ì…˜

### ì½”ë“œ í’ˆì§ˆ ë„êµ¬

#### 1. Code Formatting

```bash
# Black: ì½”ë“œ í¬ë§¤í„°
black src/ tests/

# isort: import ì •ë ¬
isort src/ tests/
```

#### 2. Code Linting

```bash
# flake8: ë¦°íŒ…
flake8 src/ tests/

# pylint: ìƒì„¸ ë¦°íŒ…
pylint src/
```

#### 3. Type Checking

```bash
# mypy: íƒ€ì… ì²´í¬
mypy src/
```

### Pre-commit Hooks

`.pre-commit-config.yaml`:

```yaml
repos:
  - repo: https://github.com/psf/black
    rev: 22.3.0
    hooks:
      - id: black
        language_version: python3.9

  - repo: https://github.com/pycqa/isort
    rev: 5.10.1
    hooks:
      - id: isort

  - repo: https://github.com/pycqa/flake8
    rev: 4.0.1
    hooks:
      - id: flake8

  - repo: https://github.com/pre-commit/mirrors-mypy
    rev: v0.942
    hooks:
      - id: mypy
```

## ğŸ“‹ ê°œë°œ ê°€ì´ë“œë¼ì¸

### ì½”ë”© ìŠ¤íƒ€ì¼

#### 1. í•¨ìˆ˜ ë° í´ë˜ìŠ¤ ëª…ëª…

```python
# ì¢‹ì€ ì˜ˆ
class NetworkDataCollector:
    async def collect_active_connections(self) -> List[ConnectionData]:
        pass

# ë‚˜ìœ ì˜ˆ
class NDC:
    def get_data(self):
        pass
```

#### 2. íƒ€ì… íŒíŠ¸ ì‚¬ìš©

```python
from typing import List, Dict, Optional, Union
from datetime import datetime

class ConnectionAnalyzer:
    def analyze_connection(
        self,
        connection: ConnectionData,
        historical_data: Optional[List[ConnectionData]] = None
    ) -> AnalysisResult:
        """ë„¤íŠ¸ì›Œí¬ ì—°ê²° ë¶„ì„"""
        pass
```

#### 3. ì—ëŸ¬ ì²˜ë¦¬

```python
from src.utils.exceptions import CollectionError, ModelError

class NetworkCollector:
    async def collect_data(self) -> List[ConnectionData]:
        try:
            # ë°ì´í„° ìˆ˜ì§‘ ë¡œì§
            return data
        except psutil.Error as e:
            raise CollectionError(f"Failed to collect network data: {e}") from e
        except Exception as e:
            self.logger.error(f"Unexpected error: {e}")
            raise
```

### ë¹„ë™ê¸° í”„ë¡œê·¸ë˜ë° íŒ¨í„´

#### 1. AsyncIO ì‚¬ìš©

```python
import asyncio
from typing import AsyncGenerator

class RealTimeCollector:
    async def collect_stream(self) -> AsyncGenerator[ConnectionData, None]:
        """ì‹¤ì‹œê°„ ë°ì´í„° ìŠ¤íŠ¸ë¦¼"""
        while True:
            try:
                data = await self._collect_current_data()
                yield data
                await asyncio.sleep(self.collection_interval)
            except Exception as e:
                self.logger.error(f"Collection error: {e}")
                await asyncio.sleep(1)  # ì¬ì‹œë„ ì „ ëŒ€ê¸°
```

#### 2. ë¦¬ì†ŒìŠ¤ ê´€ë¦¬

```python
import aiofiles
from contextlib import asynccontextmanager

@asynccontextmanager
async def database_transaction():
    """ë°ì´í„°ë² ì´ìŠ¤ íŠ¸ëœì­ì…˜ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
    conn = await get_database_connection()
    try:
        async with conn.begin():
            yield conn
    except Exception:
        await conn.rollback()
        raise
    finally:
        await conn.close()
```

## ğŸ§ª í…ŒìŠ¤íŠ¸ ì‘ì„± ê°€ì´ë“œ

### í…ŒìŠ¤íŠ¸ êµ¬ì¡°

#### 1. ë‹¨ìœ„ í…ŒìŠ¤íŠ¸

```python
import pytest
from unittest.mock import AsyncMock, patch
from src.collectors.network_collector import NetworkCollector

class TestNetworkCollector:
    @pytest.fixture
    def collector(self):
        return NetworkCollector(collection_interval=1.0)

    @pytest.mark.asyncio
    async def test_collect_connections_success(self, collector):
        """ì •ìƒì ì¸ ì—°ê²° ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸"""
        with patch('psutil.net_connections') as mock_connections:
            mock_connections.return_value = [
                # Mock connection data
            ]

            result = await collector.collect_connections()

            assert len(result) > 0
            assert all(isinstance(conn, ConnectionData) for conn in result)

    @pytest.mark.asyncio
    async def test_collect_connections_error_handling(self, collector):
        """ì—ëŸ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        with patch('psutil.net_connections', side_effect=psutil.Error("Mock error")):
            with pytest.raises(CollectionError):
                await collector.collect_connections()
```

#### 2. í†µí•© í…ŒìŠ¤íŠ¸

```python
import pytest
from httpx import AsyncClient
from src.api.main import app

class TestAnalysisAPI:
    @pytest.mark.asyncio
    async def test_analyze_endpoint(self):
        """ë¶„ì„ API í†µí•© í…ŒìŠ¤íŠ¸"""
        async with AsyncClient(app=app, base_url="http://test") as client:
            test_data = {
                "process_id": 1234,
                "process_name": "test.exe",
                # ... ê¸°íƒ€ í•„ë“œ
            }

            response = await client.post("/api/v1/analyze", json=test_data)

            assert response.status_code == 200
            result = response.json()
            assert "is_anomaly" in result["result"]
            assert "anomaly_score" in result["result"]
```

### í…ŒìŠ¤íŠ¸ ì‹¤í–‰

```bash
# ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰
pytest

# íŠ¹ì • í…ŒìŠ¤íŠ¸ ì‹¤í–‰
pytest tests/unit/test_collectors.py::TestNetworkCollector::test_collect_connections

# ì»¤ë²„ë¦¬ì§€ í¬í•¨ ì‹¤í–‰
pytest --cov=src --cov-report=html

# ë³‘ë ¬ ì‹¤í–‰
pytest -n 4
```

## ğŸ”§ ê°œë°œ ë„êµ¬

### IDE ì„¤ì • (VS Code)

#### settings.json

```json
{
  "python.defaultInterpreterPath": "./venv/Scripts/python.exe",
  "python.formatting.provider": "black",
  "python.linting.enabled": true,
  "python.linting.flake8Enabled": true,
  "python.linting.mypyEnabled": true,
  "editor.formatOnSave": true
}
```

#### í™•ì¥ í”„ë¡œê·¸ë¨

- Python
- Pylance
- Python Docstring Generator
- GitLens
- Thunder Client (API í…ŒìŠ¤íŠ¸)

### ë””ë²„ê¹… ì„¤ì •

#### launch.json

```json
{
  "version": "0.2.0",
  "configurations": [
    {
      "name": "Python: FastAPI",
      "type": "python",
      "request": "launch",
      "module": "uvicorn",
      "args": [
        "src.api.main:app",
        "--host",
        "0.0.0.0",
        "--port",
        "8000",
        "--reload"
      ],
      "console": "integratedTerminal",
      "cwd": "${workspaceFolder}"
    },
    {
      "name": "Python: Current File",
      "type": "python",
      "request": "launch",
      "program": "${file}",
      "console": "integratedTerminal",
      "cwd": "${workspaceFolder}"
    }
  ]
}
```

## ğŸ“Š ì„±ëŠ¥ ë° ëª¨ë‹ˆí„°ë§

### í”„ë¡œíŒŒì¼ë§

```python
import cProfile
import pstats
from functools import wraps

def profile_function(func):
    """í•¨ìˆ˜ í”„ë¡œíŒŒì¼ë§ ë°ì½”ë ˆì´í„°"""
    @wraps(func)
    async def wrapper(*args, **kwargs):
        pr = cProfile.Profile()
        pr.enable()
        try:
            result = await func(*args, **kwargs)
            return result
        finally:
            pr.disable()
            stats = pstats.Stats(pr)
            stats.sort_stats('cumulative')
            stats.print_stats(10)  # ìƒìœ„ 10ê°œ ì¶œë ¥
    return wrapper
```

### ë©”íŠ¸ë¦­ ìˆ˜ì§‘

```python
from prometheus_client import Counter, Histogram, start_http_server
import time

# ë©”íŠ¸ë¦­ ì •ì˜
request_count = Counter('requests_total', 'Total requests', ['method', 'endpoint'])
request_duration = Histogram('request_duration_seconds', 'Request duration')

def track_performance(func):
    """ì„±ëŠ¥ ì¶”ì  ë°ì½”ë ˆì´í„°"""
    @wraps(func)
    async def wrapper(*args, **kwargs):
        start_time = time.time()
        try:
            result = await func(*args, **kwargs)
            return result
        finally:
            duration = time.time() - start_time
            request_duration.observe(duration)
    return wrapper
```

## ğŸš€ ë°°í¬ ì¤€ë¹„

### Docker ì„¤ì •

#### Dockerfile

```dockerfile
FROM python:3.9-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY src/ ./src/
COPY config/ ./config/

EXPOSE 8000

CMD ["uvicorn", "src.api.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

#### docker-compose.yml

```yaml
version: "3.8"

services:
  network-ai-service:
    build: .
    ports:
      - "8000:8000"
    environment:
      - ENVIRONMENT=production
      - DATABASE_URL=sqlite:///./data/network_ai.db
    volumes:
      - ./data:/app/data
      - ./models:/app/models
      - ./logs:/app/logs
    restart: unless-stopped

  prometheus:
    image: prom/prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./config/prometheus.yml:/etc/prometheus/prometheus.yml

  grafana:
    image: grafana/grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
```

### CI/CD íŒŒì´í”„ë¼ì¸

#### GitHub Actions (.github/workflows/ci.yml)

```yaml
name: CI/CD Pipeline

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: 3.9

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install -r requirements-dev.txt

      - name: Run linting
        run: |
          flake8 src/ tests/
          mypy src/

      - name: Run tests
        run: |
          pytest --cov=src --cov-report=xml

      - name: Upload coverage
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage.xml

  deploy:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'

    steps:
      - uses: actions/checkout@v3

      - name: Build Docker image
        run: docker build -t network-ai-service .

      - name: Deploy to production
        run: |
          # ë°°í¬ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
          ./scripts/deploy.sh
```

ì´ ê°œë°œ ê°€ì´ë“œë¥¼ ë”°ë¼ ì¼ê´€ì„± ìˆê³  í’ˆì§ˆ ë†’ì€ ì½”ë“œë¥¼ ì‘ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
